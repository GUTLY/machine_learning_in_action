{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 决策树的构造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 信息增益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createDataSet():\n",
    "    \"\"\"创建数据集\"\"\"\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    #change to discrete values\n",
    "    return dataSet, labels\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    \"\"\"计算给定数据集的香农熵\"\"\"\n",
    "    # 数据集实例数\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    # 记录每个类别出现的次数\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys(): labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    # 计算香农熵\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        # 选择该分类的概率\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob, 2) \n",
    "    return shannonEnt\n",
    "\n",
    "myDat, labels = createDataSet()\n",
    "calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3709505944546687"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 熵越高，则混合的数据也越多，我们可以在数据集中添加更多的分类，\n",
    "myDat[0][-1]='maybe'\n",
    "calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def splitDataSet(dataSet, axis, value):\n",
    "    \"\"\"按照给定特征划分数据集\n",
    "    \n",
    "    :param dataSet: 待划分的数据集.\n",
    "    :param axis: 划分数据集的特征.\n",
    "    :param value: 需要返回的特征的值.\n",
    "    :return: : retDataSet\n",
    "    \"\"\"\n",
    "    # 新建返回数据集\n",
    "    retDataSet = []\n",
    "    # 遍历数据集\n",
    "    for featVec in dataSet:\n",
    "        # 抽取符合特征的数据\n",
    "        if featVec[axis] == value:\n",
    "            # 删除axis特征\n",
    "            reducedFeatVec = featVec[:axis]    \n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "\n",
    "myDat, labels = createDataSet()\n",
    "splitDataSet(myDat, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'no']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitDataSet(myDat, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在函数中调用的数据需要满足一定的要求\n",
    "# 第一个要求是，数据必须是一种由列表元素组成的列表，而且所有的列表元素都要具有相同的数据长度；\n",
    "# 第二个要求是，数据的最后一列或者每个实例的最后一个元素是当前实例的类别标签。\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    \"\"\"选择最好的数据集划分方式\"\"\"\n",
    "    \n",
    "    numFeatures = len(dataSet[0]) - 1      #the last column is used for the labels\n",
    "    # 计算数据集的原始香农熵\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain = 0.0; \n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):        #iterate over all the features\n",
    "        featList = [example[i] for example in dataSet]#create a list of all the examples of this feature\n",
    "        uniqueVals = set(featList)       #get a set of unique values\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        infoGain = baseEntropy - newEntropy     #calculate the info gain; ie reduction in entropy\n",
    "        if (infoGain > bestInfoGain):       #compare this to the best gain so far\n",
    "            bestInfoGain = infoGain         #if better than current best, set to best\n",
    "            bestFeature = i\n",
    "    return bestFeature                      #returns an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
